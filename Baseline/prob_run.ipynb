{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03530989-4467-453b-93d7-2ac0a39104b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: lmodel/prob/News_prob_NEW.pkl\tMAE: 0.11843706234176962\n",
      "Model: lmodel/prob/Wikinews_prob_NEW.pkl\tMAE: 0.11779519861671522\n",
      "Model: lmodel/prob/Wikipedia_prob_NEW.pkl\tMAE: 0.11918676171268122\n",
      "Model: lmodel/prob/Combined_prob_NEW.pkl\tMAE: 0.11821856043100747\n"
     ]
    }
   ],
   "source": [
    "#1 \n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_models(classifiers, testing_features):  # testing_features is now a DataFrame\n",
    "    \n",
    "\n",
    "    # Extract the feature columns from the testing features DataFrame\n",
    "    feature_columns = ['syllables', 'characters', 'vowels', 'simple_wiki_freq', 'HIT_count', 'absTotalMatchCount', 'relTotalMatchCount']\n",
    "    X_test = testing_features[feature_columns].values\n",
    "\n",
    "    # Replace NaN values with 0\n",
    "    imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "    X_test = imputer.fit_transform(X_test)\n",
    "\n",
    "    # Create an empty DataFrame to store the predictions\n",
    "    predictions_df = pd.DataFrame()\n",
    "\n",
    "    for classifier_file in classifiers:\n",
    "        # Load the trained model from the pickle file\n",
    "        with open(classifier_file, 'rb') as file:\n",
    "            classifier = pickle.load(file)\n",
    "\n",
    "        # Make predictions using the model\n",
    "        y_pred = classifier.predict(X_test)\n",
    "\n",
    "        # Add the predictions to the DataFrame\n",
    "        predictions_df[classifier_file] = y_pred\n",
    "\n",
    "    # Add the 'complex_probabilistic' label from the testing features file to the DataFrame\n",
    "    predictions_df['complex_probabilistic'] = testing_features['complex_probabilistic'].values\n",
    "\n",
    "    return predictions_df\n",
    "\n",
    "def evaluate(predictions_df):\n",
    "    # Get the predicted values and actual labels\n",
    "    y_pred = predictions_df['complex_probabilistic']\n",
    "    y_true = testing_features ['complex_probabilistic'] \n",
    "\n",
    "    # Calculate MAE for each model\n",
    "    mae_per_model = {}\n",
    "    for column in predictions_df.columns[:-1]:\n",
    "        mae = mean_absolute_error(y_true, predictions_df[column])\n",
    "        mae_per_model[column] = mae\n",
    "\n",
    "    return mae_per_model\n",
    "\n",
    "# Define the trained classifier files\n",
    "classifiers = [\n",
    "    \"lmodel/prob/News_prob_NEW.pkl\",\n",
    "    \"lmodel/prob/Wikinews_prob_NEW.pkl\",\n",
    "    \"lmodel/prob/Wikipedia_prob_NEW.pkl\",\n",
    "    \"lmodel/prob/Combined_prob_NEW.pkl\"\n",
    "]\n",
    "\n",
    "# Define the testing features file\n",
    "testing_features_file = \"features_NEW/Wikipedia_Dev_NEW_Feats1.pkl\"\n",
    "testing_features = pd.read_pickle(testing_features_file)\n",
    "\n",
    "# Run the models and make predictions\n",
    "predictions_df = run_models(classifiers, testing_features)\n",
    "\n",
    "# Evaluate the predictions using MAE for each model\n",
    "mae_per_model = evaluate(predictions_df)\n",
    "\n",
    "# Print the MAE for each model\n",
    "for model, mae in mae_per_model.items():\n",
    "    print(f\"Model: {model}\\tMAE: {mae}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ff1d15-b9cb-42de-8fee-5b5d22d4824b",
   "metadata": {},
   "source": [
    "Model: lmodel/prob/News_prob.pkl\tMAE: 0.11361416574728281\n",
    "Model: lmodel/prob/Wikinews_prob.pkl\tMAE: 0.11148948763200345\n",
    "Model: lmodel/prob/Wikipedia_prob.pkl\tMAE: 0.11352341079626468\n",
    "Model: lmodel/prob/Combined_prob.pkl\tMAE: 0.11281649160711754"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ada1b35f-e4bd-44eb-a737-32f35bb78878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{MAE per Model - features_NEW/News_Dev_NEW_Feats1.pkl}\n",
      "\\label{table:features_NEW/News_Dev_NEW_Feats1.pkl}\n",
      "\\begin{tabular}{lr}\n",
      "\\toprule\n",
      "    Model &      MAE \\\\\n",
      "\\midrule\n",
      "     NEWS & 0.113614 \\\\\n",
      " WIKINEWS & 0.111489 \\\\\n",
      "WIKIPEDIA & 0.113523 \\\\\n",
      " Combined & 0.112816 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qm/g52sxk4d4qsg16xphqz6vvtc0000gn/T/ipykernel_20074/2683669832.py:19: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = mae_df.to_latex(index=False, caption=f\"MAE per Model - {testing_feature_file}\", label=f\"table:{testing_feature_file}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NEWS': 0.11361416574728281,\n",
       " 'WIKINEWS': 0.11148948763200345,\n",
       " 'WIKIPEDIA': 0.11352341079626468,\n",
       " 'Combined': 0.11281649160711754}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate(predictions_df, testing_feature_file):\n",
    "    # Get the predicted values and actual labels\n",
    "    y_pred = predictions_df['complex_probabilistic']\n",
    "    y_true = testing_features ['complex_probabilistic'] \n",
    "\n",
    "    # Define the model names\n",
    "    model_names = [\"NEWS\", \"WIKINEWS\", \"WIKIPEDIA\", \"Combined\"]\n",
    "\n",
    "    # Calculate MAE for each model\n",
    "    mae_per_model = {}\n",
    "    for i, column in enumerate(predictions_df.columns[:-1]):\n",
    "        mae = mean_absolute_error(y_true, predictions_df[column])\n",
    "        mae_per_model[model_names[i]] = mae\n",
    "\n",
    "    # Create a DataFrame to store the MAE per model\n",
    "    mae_df = pd.DataFrame(list(mae_per_model.items()), columns=['Model', 'MAE'])\n",
    "\n",
    "    # Print the MAE DataFrame in LaTeX format\n",
    "    latex_table = mae_df.to_latex(index=False, caption=f\"MAE per Model - {testing_feature_file}\", label=f\"table:{testing_feature_file}\")\n",
    "    print(latex_table)\n",
    "\n",
    "    return mae_per_model\n",
    "evaluate(predictions_df, testing_features_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5125cb0-f890-4b5e-8b0e-8da1683ef15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lmodel/prob/News_prob.pkl': 0.008393695824554678, 'lmodel/prob/Wikinews_prob.pkl': 0.006723632283289598, 'lmodel/prob/Wikipedia_prob.pkl': 0.009716911911144625, 'lmodel/prob/Combined_prob.pkl': 0.0030427213866589574}\n"
     ]
    }
   ],
   "source": [
    "print(mae_per_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc39c558-c8d4-4b3b-8e3c-44a3f8499752",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
