{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bae48be4-94f8-4f15-a185-8c2fd3e3ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0916aa4-528c-4d8b-9d5e-f210d7802a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the feature files into non-native and native annoations. If a phrase was selected as complex \n",
    "\n",
    "\n",
    "def split_pkl_files(directory_path):\n",
    "    # Get all .pkl files in the directory\n",
    "    files = [f for f in os.listdir(directory_path) if f.endswith('_Final')]\n",
    "\n",
    "    for file in files:\n",
    "        # Create full file path\n",
    "        file_path = os.path.join(directory_path, file)\n",
    "        with open(file_path, 'rb') as f:\n",
    "            df = pickle.load(f)\n",
    "        \n",
    "        # Split DataFrame into 'Native' and 'Non-Native' parts\n",
    "        # Make sure 'Native' doesn't contain any value other than 0 in the 'non_native_complex' column\n",
    "        df_native = df[(df['native_complex'].notnull()) & ((df['non_native_complex'].isnull()) | (df['non_native_complex'] == 0))]\n",
    "        \n",
    "        # Make sure 'Non_Native' doesn't contain any value other than 0 in the 'native_complex' column\n",
    "        df_non_native = df[(df['non_native_complex'].notnull()) & ((df['native_complex'].isnull()) | (df['native_complex'] == 0))]\n",
    "\n",
    "        # Create new file names\n",
    "        base_file_name = file.rsplit('.', 1)[0]\n",
    "        native_file_name = 'Native_' + base_file_name\n",
    "        non_native_file_name = 'Non_Native_' + base_file_name\n",
    "        \n",
    "        # Create subdirectories if they don't exist\n",
    "        native_csv_subdir = os.path.join(directory_path, 'Native', 'CSV')\n",
    "        non_native_csv_subdir = os.path.join(directory_path, 'Non_Native', 'CSV')\n",
    "        os.makedirs(native_csv_subdir, exist_ok=True)\n",
    "        os.makedirs(non_native_csv_subdir, exist_ok=True)\n",
    "\n",
    "        # Save the split DataFrames to new .csv files within the subfolders\n",
    "        native_csv_file_path = os.path.join(native_csv_subdir, native_file_name + '.csv')\n",
    "        non_native_csv_file_path = os.path.join(non_native_csv_subdir, non_native_file_name + '.csv')\n",
    "        \n",
    "        df_native.to_csv(native_csv_file_path, index=False)\n",
    "        df_non_native.to_csv(non_native_csv_file_path, index=False)\n",
    "\n",
    "        # Save the split DataFrames back to new .pkl files in the current directory\n",
    "        native_pkl_file_path = os.path.join(directory_path, native_file_name + '.pkl')\n",
    "        non_native_pkl_file_path = os.path.join(directory_path, non_native_file_name + '.pkl')\n",
    "        \n",
    "        with open(native_pkl_file_path, 'wb') as f:\n",
    "            pickle.dump(df_native, f)\n",
    "            \n",
    "        with open(non_native_pkl_file_path, 'wb') as f:\n",
    "            pickle.dump(df_non_native, f)\n",
    "\n",
    "\n",
    "# Call the function with the directory containing your .pkl files\n",
    "split_pkl_files('../camb_model/cwi_2018-master/final_camb_feats_Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "932f7beb-b48e-4300-9aff-ed5b7ed2346e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/adamtucker/Desktop/CWI_masters/Camb_A\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57c48ce1-6fb4-4128-856d-94907fdf3470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works for A1 EFCAMDAT data \n",
    "\n",
    "# Write seperate functionsfor each level get_A1_freq \n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_cefr_freq_A1(folder_path, phrase_column_name='phrase', text_corrected_column_name='text_corrected'):\n",
    "    # Get the list of .pkl files in the folder\n",
    "    pkl_files = [file for file in os.listdir(folder_path) if file.endswith('.pkl')]\n",
    "\n",
    "    # Load the data from \"Corpus/EFCAMDAT_A1.pkl\" to get the phrase frequency\n",
    "    path_to_corpus = os.path.join(folder_path, '../Corpus/EFCAMDAT_A1.pkl')\n",
    "    corpus_data = pd.read_pickle(path_to_corpus)\n",
    "\n",
    "    # Create a dictionary to store the word frequencies from the \"text_corrected\" column\n",
    "    word_freq_dict = dict(corpus_data[text_corrected_column_name].str.split(expand=True).stack().value_counts())\n",
    "\n",
    "    # Iterate through each .pkl file and add the frequency column\n",
    "    for pkl_file in pkl_files:\n",
    "        if pkl_file == 'EFCAMDAT_A1.pkl':\n",
    "            # Skip the \"Corpus/EFCAMDAT_A1.pkl\" file since it doesn't need any frequency counting\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(folder_path, pkl_file)\n",
    "        df = pd.read_pickle(file_path)\n",
    "\n",
    "        # Count the occurrences of each word from the \"phrase\" column in the \"text_corrected\" column\n",
    "        df['A1_freq'] = df[phrase_column_name].apply(lambda x: sum(word_freq_dict.get(word, 0) for word in x.split()))\n",
    "\n",
    "        # Save the modified DataFrame back to the .pkl file with \"_EFCAMDAT\" added to the filename\n",
    "        new_file_path_pkl = file_path.replace(\".pkl\", \"_EFCAMDAT.pkl\")\n",
    "        df.to_pickle(new_file_path_pkl)\n",
    "\n",
    "        # Save the modified DataFrame as a .csv file with \"_EFCAMDAT\" added to the filename\n",
    "        new_file_path_csv = file_path.replace(\".pkl\", \"_EFCAMDAT.csv\")\n",
    "        df.to_csv(new_file_path_csv, index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = \"Lang8_feat_test/\"\n",
    "    get_cefr_freq(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c09da4d-5c53-4e2e-8bd8-687cb71ffdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to return frequency of target phrase in each cefr corpus\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_cefr_freq_A1(folder_path, phrase_column_name='phrase', text_corrected_column_name='text_corrected'):\n",
    "    return get_cefr_freq(folder_path, phrase_column_name, text_corrected_column_name, 'EFCAMDAT_A1.pkl', 'A1_freq')\n",
    "\n",
    "def get_cefr_freq_A2(folder_path, phrase_column_name='phrase', text_corrected_column_name='text_corrected'):\n",
    "    return get_cefr_freq(folder_path, phrase_column_name, text_corrected_column_name, 'EFCAMDAT_A2.pkl', 'A2_freq')\n",
    "\n",
    "def get_cefr_freq_B1(folder_path, phrase_column_name='phrase', text_corrected_column_name='text_corrected'):\n",
    "    return get_cefr_freq(folder_path, phrase_column_name, text_corrected_column_name, 'EFCAMDAT_B1.pkl', 'B1_freq')\n",
    "\n",
    "def get_cefr_freq_B2(folder_path, phrase_column_name='phrase', text_corrected_column_name='text_corrected'):\n",
    "    return get_cefr_freq(folder_path, phrase_column_name, text_corrected_column_name, 'EFCAMDAT_B2.pkl', 'B2_freq')\n",
    "\n",
    "def get_cefr_freq_C1(folder_path, phrase_column_name='phrase', text_corrected_column_name='text_corrected'):\n",
    "    return get_cefr_freq(folder_path, phrase_column_name, text_corrected_column_name, 'EFCAMDAT_C1.pkl', 'C1_freq')\n",
    "\n",
    "def get_cefr_freq(folder_path, phrase_column_name, text_corrected_column_name, cefr_file, cefr_freq_column):\n",
    "    # Load the data from the specified cefr_file to get the phrase frequency\n",
    "    path_to_corpus = os.path.join(folder_path, '../Corpus', cefr_file)\n",
    "    corpus_data = pd.read_pickle(path_to_corpus)\n",
    "\n",
    "    # Create a dictionary to store the word frequencies from the \"text_corrected\" column\n",
    "    word_freq_dict = dict(corpus_data[text_corrected_column_name].str.split(expand=True).stack().value_counts())\n",
    "\n",
    "    # Initialize an empty DataFrame to store the merged results\n",
    "    merged_df = pd.DataFrame()\n",
    "\n",
    "    # Iterate through each .pkl file and add the frequency column\n",
    "    for pkl_file in os.listdir(folder_path):\n",
    "        if pkl_file.endswith('.pkl') and pkl_file != cefr_file:\n",
    "            file_path = os.path.join(folder_path, pkl_file)\n",
    "            df = pd.read_pickle(file_path)\n",
    "\n",
    "            # Count the occurrences of each word from the \"phrase\" column in the \"text_corrected\" column\n",
    "            df[cefr_freq_column] = df[phrase_column_name].apply(lambda x: sum(word_freq_dict.get(word, 0) for word in x.split()))\n",
    "\n",
    "            # Add the DataFrame to the merged DataFrame\n",
    "            merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "\n",
    "    # Save the merged DataFrame to a single .pkl file\n",
    "    merged_file_path_pkl = os.path.join(folder_path, f\"merged_{cefr_file}\")\n",
    "    merged_df.to_pickle(merged_file_path_pkl)\n",
    "\n",
    "    # Save the merged DataFrame to a single .csv file\n",
    "    merged_file_path_csv = os.path.join(folder_path, f\"merged_{cefr_file.replace('.pkl', '.csv')}\")\n",
    "    merged_df.to_csv(merged_file_path_csv, index=False)\n",
    "\n",
    "# Usage example:\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = \"Lang8_feat_test/\"\n",
    "    get_cefr_freq_A1(folder_path)\n",
    "    get_cefr_freq_A2(folder_path)\n",
    "    get_cefr_freq_B1(folder_path)\n",
    "    get_cefr_freq_B2(folder_path)\n",
    "    get_cefr_freq_C1(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13b7d38-92ba-421a-b78f-f320638a519c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
